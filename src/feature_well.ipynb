{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '../dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_test_id(df, test_ids):\n",
    "    \n",
    "    test_set = df.iloc[test_ids]\n",
    "    test_y = test_set[['education_type']]\n",
    "    test_x = test_set.drop('education_type', axis=1)\n",
    "\n",
    "    train_set = df.drop(test_ids, axis=0)\n",
    "    train_y = train_set[['education_type']]\n",
    "    train_x = train_set.drop('education_type', axis=1)\n",
    "    \n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_df = pd.read_csv(os.path.join(data_folder, 'feature_df_2.csv'))\n",
    "with open(os.path.join(data_folder, 'test_node.txt')) as f:\n",
    "    test_ids = [int(node.strip()) for node in f.readlines()]\n",
    "\n",
    "train_x, train_y, test_x, test_y = split_by_test_id(global_df, test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_test: 0.8761904761904762\n",
      "[0.84731774 0.87052342 0.87327824 0.85931034 0.83287293]\n",
      "0.8566605340102003\n"
     ]
    }
   ],
   "source": [
    "# Linear Model -- Softmax\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', solver='saga', multi_class='multinomial')\n",
    "lr.fit(train_x, train_y)\n",
    "y_pred = lr.predict(test_x)\n",
    "accu = accuracy_score(test_y, y_pred)\n",
    "print('train_test:', accu)\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', solver='saga', multi_class='multinomial')\n",
    "cv_val = cross_val_score(lr, train_x, train_y, cv=5)\n",
    "print('cv:', cv_val)\n",
    "print('cv:', np.average(cv_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_test: 0.8833333333333333\n",
      "cv: [0.80055021 0.86501377 0.87878788 0.8662069  0.84116022]\n",
      "cv: 0.8503437953532268\n"
     ]
    }
   ],
   "source": [
    "# XGBoost Classidier\n",
    "\n",
    "xgb_clf = XGBClassifier(max_depth=3,\n",
    "                        n_estimators=1000,  \n",
    "                        objective='multi:softprob',\n",
    "                        seed=0, \n",
    "                        silent=True, \n",
    "                        learning_rate=0.001)\n",
    "xgb_clf.fit(train_x, train_y)\n",
    "y_pred = xgb_clf.predict(test_x)\n",
    "accu = accuracy_score(test_y, y_pred)\n",
    "print('train_test:', accu)\n",
    "\n",
    "xgb_clf = XGBClassifier(max_depth=3,\n",
    "                        n_estimators=1000,  \n",
    "                        objective='multi:softprob',\n",
    "                        seed=0, \n",
    "                        silent=True, \n",
    "                        learning_rate=0.001)\n",
    "xgb_clf.fit(train_x, train_y)\n",
    "cv_val = cross_val_score(xgb_clf, train_x, train_y, cv=5)\n",
    "print('cv:', cv_val)\n",
    "print('cv:', np.average(cv_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global with local Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_local_df = pd.read_csv(os.path.join(data_folder, 'feature_df_3.csv'))\n",
    "with open(os.path.join(data_folder, 'test_node.txt')) as f:\n",
    "    test_ids = [int(node.strip()) for node in f.readlines()]\n",
    "\n",
    "train_x, train_y, test_x, test_y = split_by_test_id(global_local_df, test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_test: 0.8761904761904762\n",
      "cv: [0.84731774 0.87052342 0.87327824 0.85931034 0.83287293]\n",
      "cv: 0.8566605340102003\n"
     ]
    }
   ],
   "source": [
    "# Linear Model -- Softmax\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', solver='saga', multi_class='multinomial')\n",
    "lr.fit(train_x, train_y)\n",
    "y_pred = lr.predict(test_x)\n",
    "accu = accuracy_score(test_y, y_pred)\n",
    "print('train_test:', accu)\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', solver='saga', multi_class='multinomial')\n",
    "cv_val = cross_val_score(lr, train_x, train_y, cv=5)\n",
    "print('cv:', cv_val)\n",
    "print('cv:', np.average(cv_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_test: 0.8833333333333333\n",
      "cv: [0.80192572 0.86501377 0.87878788 0.8662069  0.83701657]\n",
      "cv: 0.8497901692351453\n"
     ]
    }
   ],
   "source": [
    "# XGBoost Classidier\n",
    "\n",
    "xgb_clf = XGBClassifier(max_depth=3,\n",
    "                        n_estimators=1000,  \n",
    "                        objective='multi:softprob',\n",
    "                        seed=0, \n",
    "                        silent=True, \n",
    "                        learning_rate=0.001)\n",
    "xgb_clf.fit(train_x, train_y)\n",
    "y_pred = xgb_clf.predict(test_x)\n",
    "accu = accuracy_score(test_y, y_pred)\n",
    "print('train_test:', accu)\n",
    "\n",
    "xgb_clf = XGBClassifier(max_depth=3,\n",
    "                        n_estimators=1000,  \n",
    "                        objective='multi:softprob',\n",
    "                        seed=0, \n",
    "                        silent=True, \n",
    "                        learning_rate=0.001)\n",
    "xgb_clf.fit(train_x, train_y)\n",
    "cv_val = cross_val_score(xgb_clf, train_x, train_y, cv=5)\n",
    "print('cv:', cv_val)\n",
    "print('cv:', np.average(cv_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 这里看出local info 主要是引入了噪声"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global with Shortest Path Mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_folder, 'test_node.txt')) as f:\n",
    "    test_ids = [int(node.strip()) for node in f.readlines()]\n",
    "    \n",
    "global_df = pd.read_csv(os.path.join(data_folder, 'feature_df_2.csv'))\n",
    "    \n",
    "shortest_paths = pd.read_csv(os.path.join(data_folder, 'shortest_path.csv'))\n",
    "pca = PCA(n_components=10, svd_solver='randomized')\n",
    "pca_spm = pca.fit_transform(shortest_paths)\n",
    "pca_spm = pd.DataFrame(pca_spm)\n",
    "# pca_spm['education_type'] = feature_global['education_type']\n",
    "\n",
    "global_sp_df = pd.concat([global_df, pca_spm], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = split_by_test_id(global_sp_df, test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_test: 0.8785714285714286\n",
      "cv: [0.46217331 0.74793388 0.71349862 0.85793103 0.67265193]\n",
      "cv: 0.6908377580129181\n"
     ]
    }
   ],
   "source": [
    "# Linear Model -- Softmax\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', solver='saga', multi_class='multinomial')\n",
    "lr.fit(train_x, train_y)\n",
    "y_pred = lr.predict(test_x)\n",
    "accu = accuracy_score(test_y, y_pred)\n",
    "print('train_test:', accu)\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', solver='saga', multi_class='multinomial')\n",
    "cv_val = cross_val_score(lr, train_x, train_y, cv=5)\n",
    "print('cv:', cv_val)\n",
    "print('cv:', np.average(cv_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_test: 0.8833333333333333\n",
      "cv: [0.57083906 0.86501377 0.87878788 0.8662069  0.81629834]\n",
      "cv: 0.7994291913269931\n"
     ]
    }
   ],
   "source": [
    "# XGBoost Classidier\n",
    "\n",
    "xgb_clf = XGBClassifier(max_depth=3,\n",
    "                        n_estimators=1000,  \n",
    "                        objective='multi:softprob',\n",
    "                        seed=0, \n",
    "                        silent=True, \n",
    "                        learning_rate=0.001)\n",
    "xgb_clf.fit(train_x, train_y)\n",
    "y_pred = xgb_clf.predict(test_x)\n",
    "accu = accuracy_score(test_y, y_pred)\n",
    "print('train_test:', accu)\n",
    "\n",
    "xgb_clf = XGBClassifier(max_depth=3,\n",
    "                        n_estimators=1000,  \n",
    "                        objective='multi:softprob',\n",
    "                        seed=0, \n",
    "                        silent=True, \n",
    "                        learning_rate=0.001)\n",
    "xgb_clf.fit(train_x, train_y)\n",
    "cv_val = cross_val_score(xgb_clf, train_x, train_y, cv=5)\n",
    "print('cv:', cv_val)\n",
    "print('cv:', np.average(cv_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
